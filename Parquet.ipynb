{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b9953b-ab13-41f3-a3fb-26eaa9666200",
   "metadata": {},
   "source": [
    "**OLAP**: (Online analytical processing) any software that performs fast multidimensional analysis on large volumes of data.\n",
    "\n",
    "**What is Apache Arrow:**\n",
    "Apache arrow is a framework for defining in-memory columanar data that every processing engine can use.\n",
    "- **processing engine** refers to a software system or framework that processes, analyzes, and transforms data. These engines are often used for tasks such as data querying, computation, and batch processing, and typically oeprate on large datasets, either in-memory or distributed systems across multiple machines.\n",
    "\n",
    "    - Eg: Apache Spark, Pandas, Apache Flink\n",
    "\n",
    "**Column database:**\n",
    "What is a column databse? As the name suggests, a column (or columnar) database stores data organized into columns instead of rows on disk. A column database organize the data so that each column value is stored next to each other sequentially on a disk. \n",
    "\n",
    "\n",
    "The main advantage of a columnar database is that it can significantly reduce the amount of space required to store the data due to improvec compression ratios. In addition, columnar databases are much faster at processing analytic-type queries than traditional row-based databases. \n",
    "### How \n",
    "**Columnar Storage Format**\n",
    "- the main technique that allows columnar databases and formats like Apache Arrow to be faster, especially for analytical queries can be attributed to their **columnar storage** and **vectorized processing**.\n",
    "\n",
    "- **Data Locality:** In a columnar format, data is stored column by column rather than row by row. This means that when a query requests data from specific columns, only those columns need to be read from disk or memory, reducing I/O overhead and improving query performance\n",
    "\n",
    "- **Efficient Data Access:** Columnar storage optimizes for read-heavy workloads typical in analytics. Since analytical queries often involve operations on a small subset of columns across many rows, the ability to access only relevant columns without reading the entire row structure is a key advantage.\n",
    "\n",
    "**Vectorized  Processing:**\n",
    " - **SIMD (Single instruction, Multiple Data):** Columnar data is well-suited for vectorized processing, where the same operation is applied simultaneously to a block of data. This leverages the modern CPU architectures to process multiple data points in a single instruction \n",
    "\n",
    "- being able to use optimal compression algorithms for each data type because each column is the same type rather than a row of mixed data types. This not only reduces storage cost on disk but improves performance because fewer disk seeks are needed, and more data can fit into RAM.\n",
    "\n",
    "- **Cache efficciency** The columnar format enhances cache efficiency because data in a single column is stored contiguously. This leads to better cache utilization, reducing the need for frequent memory fetches and speeding up data processing.\n",
    "\n",
    "\n",
    "**Optimized Comphression:**\n",
    "- **Type-specific Compression:** columnar databases and formats like Apache Arrow can apply compression algorithms tailored to the data type of each column, leading to better comphression ratios. This reduces storage footprint and can also improve performance by reducing the amount of data that needs to be read from disk or transferred over networks.\n",
    "\n",
    "**In-Memory Processing (Apache Arrow Specific)**:\n",
    "\n",
    "- Zero-Copy Data Sharing: Apache Arrow's format allows zero-copy reads and writes across different systems and languages, avoiding overhead of serialization and deserialization. This is particularly beneficial in data pipelines where data needs to be passed between multiple processing engines\n",
    "- \n",
    "\n",
    "\n",
    "\n",
    "## Parqeut\n",
    "\n",
    "Apache Parquet is a columnar storage format for big data procesing systems. Its designed for efficient storage and fast data access, and can handle complex data structures.\n",
    "\n",
    "Parquet is an open source file format built to handle flat columnar storage data formats. Parquet operates well with complex data in large volumnes. It is known for its performant data compression and its ability to handle a wide varitey of encoding types. \n",
    "\n",
    "Parquet deploys Google's record-shredding and assembly algorithm that can address complex data strcutures within data storage. Some benefits:\n",
    "- Fast queries that can fetch specific column values without reading the full data row\n",
    "- Highly efficient column-wise compression\n",
    "- High compartibility with OLAP\n",
    "\n",
    "**Record-Shredding:** This technique breaks down complex, nested data structures (lists, maps, structs) into simpler, flat columns. Each element of the nested structure is stored in its own column, allowing the data to be stored inot a columnar format that is both space-efficient and fast to query. \n",
    "**Assembly Algorithm:** When querying the data, Parquet uses an assembly algorithm to reconstruct the orignal nested structure from these flattened columns. This process allows Parquet to efficiently store and retrieve complex data types while maintaining the benefits of columnar storage. \n",
    "\n",
    "### How is Parquet different from CSV?\n",
    "- Parquet is column oriented and CSV is row oriented. Row-oriented formats are optimized for OLTP (online transactional processing workloads while column-oriented formats are better suited for analytical workloads\n",
    "- \n",
    "\n",
    "### OLAP vs. OLTP\n",
    "- OLAP system can process large amounts of data quickly\n",
    "- OLTP systems ar desgined to handle large volumnes fo transactional data involving multiple users. Relational databases rapidly update, insert, or delete small amounts of data in real-time. Most OLTP systems are used for executing transactions such a banking transactions, hotel booking, etc..,\n",
    "\n",
    "Many OLAP systems pull their data from OLTP databases via an ETL pipeline. Simply put organizations use OLTP systems to run the business while OLAP systems help them understand it. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d985cd3-a97a-4b05-83e6-a4ca162c3807",
   "metadata": {},
   "source": [
    "### What is Parquet?\n",
    "\n",
    "Apache Parquet is an open source, column-oritented data file format for efficient data storage and retrieval. It excels in providing effective data compression and encoding schemes, which enhance performance and make it capable of handling complex, nested data structures at scale.  \n",
    "\n",
    "**Use cases:* Often used in scenarios when large datasets need to be stored  efficienlty and queried frequently. It common in environments like data lakes, data warehouses, and big data pipelines \n",
    "\n",
    "**Technical:** \n",
    "- Parquet is built from the ground up with complex nested data strcutures in mind, and uses the record shredding and assembly algorithm described in the Dermel paper.\n",
    "- Parquet is built to support very efficient compression and encoding schemes. \n",
    "\n",
    "\n",
    "\n",
    "**Compression** is the process of reducing the size of data to save storage space and redudce the time it takes to read or write data to disk. But what you're giving up is the CPU cycles. The trade off is between CPU(for compression/decompression)vs. IO  I/O operations (for reading/writing data)\n",
    "\n",
    "- CPU vs. I/O Trade-off: Compress = reduce the data that needs to be transferred to and from disk (I/O operations); however compression and decompression data requires CPU resources. The decsion to use compression is a balance between reducing I/O overhead and th extra CPU cycles needed for the compression process.\n",
    "\n",
    "- In an environment where I/O is the bottleneck (reading/wriing to/from disk), compression can improve overall performance despite the added CPU cost.\n",
    "\n",
    "- In contrast, if CPU resources are limited or if real-time processing is cirtical, the added CPU overhead compression might outweigh the benefits\n",
    "\n",
    "\n",
    "\n",
    "- since Parquet stores data in columnar format (i.e., column by column rather than row by row), each column contains data of the same type (integers, strings, dates). This homogeneity allows for more efficient compression.\n",
    "- Parquet supports several compression algorithms such as Snappy, GZIP, and LZO. These algorithms take advantage of repeating patterns in the data within a column to compress it more effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fca8125-3aeb-41e8-925f-c329eda22280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa   # Import pyarrow for Parquet support\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "n_rows = 1_000_000\n",
    "n_cols = 10\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    f'col{i}': np.random.randint(0, 1000, size = n_rows)\n",
    "    for i in range(n_cols)\n",
    "})\n",
    "data['category'] = np.random.choice(['A', 'B', 'C', 'D'], size = n_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6466cfdc-051d-487a-8e36-fd2fc4a8d15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>916</td>\n",
       "      <td>663</td>\n",
       "      <td>634</td>\n",
       "      <td>757</td>\n",
       "      <td>221</td>\n",
       "      <td>332</td>\n",
       "      <td>979</td>\n",
       "      <td>149</td>\n",
       "      <td>382</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>494</td>\n",
       "      <td>733</td>\n",
       "      <td>945</td>\n",
       "      <td>100</td>\n",
       "      <td>769</td>\n",
       "      <td>28</td>\n",
       "      <td>895</td>\n",
       "      <td>28</td>\n",
       "      <td>560</td>\n",
       "      <td>862</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>379</td>\n",
       "      <td>996</td>\n",
       "      <td>594</td>\n",
       "      <td>262</td>\n",
       "      <td>280</td>\n",
       "      <td>365</td>\n",
       "      <td>283</td>\n",
       "      <td>584</td>\n",
       "      <td>388</td>\n",
       "      <td>889</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>252</td>\n",
       "      <td>900</td>\n",
       "      <td>106</td>\n",
       "      <td>851</td>\n",
       "      <td>838</td>\n",
       "      <td>831</td>\n",
       "      <td>362</td>\n",
       "      <td>177</td>\n",
       "      <td>923</td>\n",
       "      <td>512</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>448</td>\n",
       "      <td>80</td>\n",
       "      <td>510</td>\n",
       "      <td>398</td>\n",
       "      <td>514</td>\n",
       "      <td>65</td>\n",
       "      <td>560</td>\n",
       "      <td>25</td>\n",
       "      <td>774</td>\n",
       "      <td>412</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>197</td>\n",
       "      <td>331</td>\n",
       "      <td>899</td>\n",
       "      <td>638</td>\n",
       "      <td>872</td>\n",
       "      <td>418</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>685</td>\n",
       "      <td>833</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>851</td>\n",
       "      <td>151</td>\n",
       "      <td>420</td>\n",
       "      <td>458</td>\n",
       "      <td>926</td>\n",
       "      <td>161</td>\n",
       "      <td>109</td>\n",
       "      <td>508</td>\n",
       "      <td>259</td>\n",
       "      <td>87</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>561</td>\n",
       "      <td>958</td>\n",
       "      <td>297</td>\n",
       "      <td>617</td>\n",
       "      <td>274</td>\n",
       "      <td>399</td>\n",
       "      <td>292</td>\n",
       "      <td>942</td>\n",
       "      <td>545</td>\n",
       "      <td>405</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>239</td>\n",
       "      <td>403</td>\n",
       "      <td>410</td>\n",
       "      <td>230</td>\n",
       "      <td>851</td>\n",
       "      <td>962</td>\n",
       "      <td>725</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>163</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>309</td>\n",
       "      <td>855</td>\n",
       "      <td>268</td>\n",
       "      <td>435</td>\n",
       "      <td>544</td>\n",
       "      <td>929</td>\n",
       "      <td>222</td>\n",
       "      <td>221</td>\n",
       "      <td>722</td>\n",
       "      <td>287</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        col0  col1  col2  col3  col4  col5  col6  col7  col8  col9 category\n",
       "0         88   916   663   634   757   221   332   979   149   382        D\n",
       "1        494   733   945   100   769    28   895    28   560   862        C\n",
       "2        379   996   594   262   280   365   283   584   388   889        C\n",
       "3        252   900   106   851   838   831   362   177   923   512        C\n",
       "4        448    80   510   398   514    65   560    25   774   412        C\n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...      ...\n",
       "999995   197   331   899   638   872   418    46    49   685   833        A\n",
       "999996   851   151   420   458   926   161   109   508   259    87        D\n",
       "999997   561   958   297   617   274   399   292   942   545   405        B\n",
       "999998   239   403   410   230   851   962   725     5    41   163        C\n",
       "999999   309   855   268   435   544   929   222   221   722   287        D\n",
       "\n",
       "[1000000 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832e91e7-adcf-45d3-9912-3f8769117f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 39.00 MB\n",
      "Time: 1.64 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# CSV\n",
    "csv_start_time = time.time()\n",
    "data.to_csv('data.csv', index = False)\n",
    "csv_end_time = time.time()\n",
    "\n",
    "print(f\"size: {os.path.getsize('data.csv') / (1024 * 1024):.2f} MB\")\n",
    "print(f\"Time: {csv_end_time - csv_start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5099e-e40a-4ef8-a9e7-c07f1dbf2861",
   "metadata": {},
   "source": [
    "## Parquet without Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3dd1c48-944f-4339-9c34-c548622f31b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 12.26 MB\n",
      "Time: 0.22 seconds\n"
     ]
    }
   ],
   "source": [
    "parquet_start_time = time.time()\n",
    "data.to_parquet('data.parquet', engine= 'pyarrow', compression = None, index = False)\n",
    "parquet_end_time = time.time()\n",
    "\n",
    "print(f\"size: {os.path.getsize('data.parquet') / (1024 * 1024):.2f} MB\")\n",
    "print(f\"Time: {parquet_end_time - parquet_start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e1c30b1-e364-4947-b9a5-814976614406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet file size (with compression): 12.23 MB\n",
      "Time taken to write Parquet (with compression): 0.22 seconds\n"
     ]
    }
   ],
   "source": [
    "# Write the DataFrame to a Parquet file with compression\n",
    "parquet_compressed_start_time = time.time()\n",
    "data.to_parquet('data_compressed.parquet', engine='pyarrow', compression='snappy', index=False)\n",
    "parquet_compressed_end_time = time.time()\n",
    "\n",
    "print(f\"Parquet file size (with compression): {os.path.getsize('data_compressed.parquet') / (1024 * 1024):.2f} MB\")\n",
    "print(f\"Time taken to write Parquet (with compression): {parquet_compressed_end_time - parquet_compressed_start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed16ca0d-c312-4663-9a1a-180c614ae61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  gender marital_status  household_income  individual_income  \\\n",
      "0   60   Other         Single      48742.636095       68943.117809   \n",
      "1   37    Male         Single      78697.969919       26020.048371   \n",
      "2   65    Male        Widowed      33917.136328       87610.882576   \n",
      "3   83  Female       Divorced      71738.193542       44953.755703   \n",
      "4   23    Male       Divorced      49044.507036       39434.799359   \n",
      "\n",
      "  income_category      province         city postal_code    employment_status  \\\n",
      "0          Middle       Alberta      Toronto     S1W 2G4           Unemployed   \n",
      "1          Middle  Saskatchewan     Winnipeg     L2F 4Z6  Not in Labour Force   \n",
      "2    Lower-Middle         Yukon      Calgary     K4K 9Y1             Employed   \n",
      "3          Middle         Yukon  Quebec City     O6H 7Y4           Unemployed   \n",
      "4    Lower-Middle      Manitoba     Edmonton     T8D 7M3           Unemployed   \n",
      "\n",
      "      occupation      industry education_level  household_size dwelling_type  \n",
      "0     Management   Agriculture        Bachelor               3         Condo  \n",
      "1       Business   Agriculture       Doctorate               2        Duplex  \n",
      "2      Education          Tech        Bachelor               2     Townhouse  \n",
      "3      Education  Construction          Master               1         House  \n",
      "4  Manufacturing          Tech      No Diploma               4         Condo  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the number of rows\n",
    "n_rows = 500_000  # Half a million entries to simulate a large census-like dataset\n",
    "\n",
    "# Generate demographic data\n",
    "demographic_data = {\n",
    "    'age': np.random.randint(18, 90, size=n_rows),  # Ages between 18 and 90\n",
    "    'gender': np.random.choice(['Male', 'Female', 'Other'], size=n_rows),  # Gender categories\n",
    "    'marital_status': np.random.choice(['Single', 'Married', 'Divorced', 'Widowed'], size=n_rows)\n",
    "}\n",
    "\n",
    "# Generate income data\n",
    "income_data = {\n",
    "    'household_income': np.random.normal(70000, 25000, size=n_rows),  # Normally distributed income\n",
    "    'individual_income': np.random.normal(40000, 15000, size=n_rows),\n",
    "    'income_category': pd.cut(np.random.normal(70000, 25000, size=n_rows),\n",
    "                              bins=[0, 30000, 60000, 100000, 150000, np.inf],\n",
    "                              labels=['Low', 'Lower-Middle', 'Middle', 'Upper-Middle', 'High'])\n",
    "}\n",
    "\n",
    "# Generate geographical data\n",
    "provinces = ['Ontario', 'Quebec', 'British Columbia', 'Alberta', 'Manitoba', \n",
    "             'Saskatchewan', 'Nova Scotia', 'New Brunswick', 'Newfoundland and Labrador', \n",
    "             'Prince Edward Island', 'Northwest Territories', 'Yukon', 'Nunavut']\n",
    "geographical_data = {\n",
    "    'province': np.random.choice(provinces, size=n_rows),\n",
    "    'city': np.random.choice(['Toronto', 'Montreal', 'Vancouver', 'Calgary', 'Edmonton', \n",
    "                              'Ottawa', 'Quebec City', 'Winnipeg', 'Halifax'], size=n_rows),\n",
    "    'postal_code': [''.join([np.random.choice(list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')),\n",
    "                             np.random.choice(list('0123456789')),\n",
    "                             np.random.choice(list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')),\n",
    "                             ' ',\n",
    "                             np.random.choice(list('0123456789')),\n",
    "                             np.random.choice(list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')),\n",
    "                             np.random.choice(list('0123456789'))])\n",
    "                    for _ in range(n_rows)]\n",
    "}\n",
    "\n",
    "# Generate employment data\n",
    "employment_data = {\n",
    "    'employment_status': np.random.choice(['Employed', 'Unemployed', 'Not in Labour Force'], size=n_rows),\n",
    "    'occupation': np.random.choice(['Management', 'Business', 'Science', 'Health', \n",
    "                                    'Education', 'Art', 'Sales', 'Trades', 'Manufacturing'], size=n_rows),\n",
    "    'industry': np.random.choice(['Agriculture', 'Manufacturing', 'Retail', 'Construction', \n",
    "                                  'Finance', 'Education', 'Healthcare', 'Tech', 'Government'], size=n_rows)\n",
    "}\n",
    "\n",
    "# Generate education data\n",
    "education_data = {\n",
    "    'education_level': np.random.choice(['No Diploma', 'High School', 'College', 'Bachelor', 'Master', 'Doctorate'], size=n_rows)\n",
    "}\n",
    "\n",
    "# Generate census data\n",
    "census_data = {\n",
    "    'household_size': np.random.randint(1, 6, size=n_rows),  # Household size between 1 and 5\n",
    "    'dwelling_type': np.random.choice(['House', 'Apartment', 'Townhouse', 'Condo', 'Duplex'], size=n_rows)\n",
    "}\n",
    "\n",
    "# Combine all data into a DataFrame\n",
    "data = pd.DataFrame({**demographic_data, **income_data, **geographical_data, \n",
    "                     **employment_data, **education_data, **census_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a3e435d-bfbd-46e8-9f0a-b9bd13534d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>household_income</th>\n",
       "      <th>individual_income</th>\n",
       "      <th>income_category</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>industry</th>\n",
       "      <th>education_level</th>\n",
       "      <th>household_size</th>\n",
       "      <th>dwelling_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>Other</td>\n",
       "      <td>Single</td>\n",
       "      <td>48742.636095</td>\n",
       "      <td>68943.117809</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>S1W 2G4</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Management</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>3</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>78697.969919</td>\n",
       "      <td>26020.048371</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>L2F 4Z6</td>\n",
       "      <td>Not in Labour Force</td>\n",
       "      <td>Business</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>2</td>\n",
       "      <td>Duplex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>Male</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>33917.136328</td>\n",
       "      <td>87610.882576</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>K4K 9Y1</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Education</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2</td>\n",
       "      <td>Townhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>Female</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>71738.193542</td>\n",
       "      <td>44953.755703</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>O6H 7Y4</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Education</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Master</td>\n",
       "      <td>1</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>49044.507036</td>\n",
       "      <td>39434.799359</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T8D 7M3</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Tech</td>\n",
       "      <td>No Diploma</td>\n",
       "      <td>4</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>75</td>\n",
       "      <td>Female</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>34158.445942</td>\n",
       "      <td>32957.425234</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>C4O 5Y1</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Business</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>1</td>\n",
       "      <td>Duplex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>77</td>\n",
       "      <td>Female</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>65678.480391</td>\n",
       "      <td>46158.309234</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Halifax</td>\n",
       "      <td>P2N 6G2</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Management</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Master</td>\n",
       "      <td>5</td>\n",
       "      <td>Townhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>60</td>\n",
       "      <td>Other</td>\n",
       "      <td>Single</td>\n",
       "      <td>67554.800350</td>\n",
       "      <td>29964.153289</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>K0P 6Q8</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Master</td>\n",
       "      <td>4</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>81</td>\n",
       "      <td>Other</td>\n",
       "      <td>Single</td>\n",
       "      <td>71621.728631</td>\n",
       "      <td>18202.168957</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>Z7O 5X8</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Management</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>No Diploma</td>\n",
       "      <td>4</td>\n",
       "      <td>Townhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>74</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>40148.527630</td>\n",
       "      <td>38115.871031</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>U2E 5Q9</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Business</td>\n",
       "      <td>Education</td>\n",
       "      <td>No Diploma</td>\n",
       "      <td>3</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender marital_status  household_income  individual_income  \\\n",
       "0        60   Other         Single      48742.636095       68943.117809   \n",
       "1        37    Male         Single      78697.969919       26020.048371   \n",
       "2        65    Male        Widowed      33917.136328       87610.882576   \n",
       "3        83  Female       Divorced      71738.193542       44953.755703   \n",
       "4        23    Male       Divorced      49044.507036       39434.799359   \n",
       "...     ...     ...            ...               ...                ...   \n",
       "499995   75  Female       Divorced      34158.445942       32957.425234   \n",
       "499996   77  Female        Widowed      65678.480391       46158.309234   \n",
       "499997   60   Other         Single      67554.800350       29964.153289   \n",
       "499998   81   Other         Single      71621.728631       18202.168957   \n",
       "499999   74  Female         Single      40148.527630       38115.871031   \n",
       "\n",
       "       income_category      province         city postal_code  \\\n",
       "0               Middle       Alberta      Toronto     S1W 2G4   \n",
       "1               Middle  Saskatchewan     Winnipeg     L2F 4Z6   \n",
       "2         Lower-Middle         Yukon      Calgary     K4K 9Y1   \n",
       "3               Middle         Yukon  Quebec City     O6H 7Y4   \n",
       "4         Lower-Middle      Manitoba     Edmonton     T8D 7M3   \n",
       "...                ...           ...          ...         ...   \n",
       "499995    Lower-Middle  Saskatchewan     Montreal     C4O 5Y1   \n",
       "499996          Middle  Saskatchewan      Halifax     P2N 6G2   \n",
       "499997          Middle      Manitoba      Toronto     K0P 6Q8   \n",
       "499998          Middle       Nunavut     Montreal     Z7O 5X8   \n",
       "499999          Middle      Manitoba     Edmonton     U2E 5Q9   \n",
       "\n",
       "          employment_status     occupation       industry education_level  \\\n",
       "0                Unemployed     Management    Agriculture        Bachelor   \n",
       "1       Not in Labour Force       Business    Agriculture       Doctorate   \n",
       "2                  Employed      Education           Tech        Bachelor   \n",
       "3                Unemployed      Education   Construction          Master   \n",
       "4                Unemployed  Manufacturing           Tech      No Diploma   \n",
       "...                     ...            ...            ...             ...   \n",
       "499995           Unemployed       Business           Tech       Doctorate   \n",
       "499996             Employed     Management  Manufacturing          Master   \n",
       "499997             Employed  Manufacturing  Manufacturing          Master   \n",
       "499998           Unemployed     Management  Manufacturing      No Diploma   \n",
       "499999             Employed       Business      Education      No Diploma   \n",
       "\n",
       "        household_size dwelling_type  \n",
       "0                    3         Condo  \n",
       "1                    2        Duplex  \n",
       "2                    2     Townhouse  \n",
       "3                    1         House  \n",
       "4                    4         Condo  \n",
       "...                ...           ...  \n",
       "499995               1        Duplex  \n",
       "499996               5     Townhouse  \n",
       "499997               4         Condo  \n",
       "499998               4     Townhouse  \n",
       "499999               3         Condo  \n",
       "\n",
       "[500000 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37485e51-16df-4b85-b223-0d5778d5ecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file size: 68.63 MB\n",
      "Time taken to write CSV: 1.73 seconds\n",
      "Parquet file size (no compression): 16.07 MB\n",
      "Time taken to write Parquet (no compression): 0.34 seconds\n",
      "Parquet file size (with Snappy): 14.43 MB\n",
      "Time taken to write Parquet (with Snappy): 0.35 seconds\n",
      "Parquet file size (with GZIP): 12.29 MB\n",
      "Time taken to write Parquet (with GZIP): 1.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# Save as CSV\n",
    "csv_start_time = time.time()\n",
    "data.to_csv('statistics_canada_data.csv', index=False)\n",
    "csv_end_time = time.time()\n",
    "\n",
    "print(f\"CSV file size: {os.path.getsize('statistics_canada_data.csv') / (1024 * 1024):.2f} MB\")\n",
    "print(f\"Time taken to write CSV: {csv_end_time - csv_start_time:.2f} seconds\")\n",
    "\n",
    "# Save as Parquet without Compression\n",
    "parquet_start_time = time.time()\n",
    "data.to_parquet('statistics_canada_data.parquet', engine='pyarrow', compression=None, index=False)\n",
    "parquet_end_time = time.time()\n",
    "\n",
    "print(f\"Parquet file size (no compression): {os.path.getsize('statistics_canada_data.parquet') / (1024 * 1024):.2f} MB\")\n",
    "print(f\"Time taken to write Parquet (no compression): {parquet_end_time - parquet_start_time:.2f} seconds\")\n",
    "\n",
    "# Save as Parquet with Snappy Compression\n",
    "snappy_start_time = time.time()\n",
    "data.to_parquet('statistics_canada_data_snappy.parquet', engine='pyarrow', compression='snappy', index=False)\n",
    "snappy_end_time = time.time()\n",
    "\n",
    "print(f\"Parquet file size (with Snappy): {os.path.getsize('statistics_canada_data_snappy.parquet') / (1024 * 1024):.2f} MB\")\n",
    "print(f\"Time taken to write Parquet (with Snappy): {snappy_end_time - snappy_start_time:.2f} seconds\")\n",
    "\n",
    "# Save as Parquet with GZIP Compression\n",
    "gzip_start_time = time.time()\n",
    "data.to_parquet('statistics_canada_data_gzip.parquet', engine='pyarrow', compression='gzip', index=False)\n",
    "gzip_end_time = time.time()\n",
    "\n",
    "print(f\"Parquet file size (with GZIP): {os.path.getsize('statistics_canada_data_gzip.parquet') / (1024 * 1024):.2f} MB\")\n",
    "print(f\"Time taken to write Parquet (with GZIP): {gzip_end_time - gzip_start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b53d8c-a99b-4e4f-b7a2-50c402d3af64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
