{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df884ea8-ca84-4a39-a4d6-f7003849a59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       business_name postal_code            city province\n",
      "0                      Copeland-Cook     R1J 6V1  North Annmouth       NS\n",
      "1                       Smith-Hoover     R9H 6P1  East Kaylafurt       BC\n",
      "2     Campoell, Frankyol and Elliktt     PxY 2A5      Port Jakes       NS\n",
      "3        Herrera, Castillo and Terry      P3N6Y4   West Michelle       BC\n",
      "4                     Beard and Sons     RdS 9L7    cesz Daleton       BC\n",
      "...                              ...         ...             ...      ...\n",
      "1495      Powell, Barrett and Gamble      X9H4A6     Baileyhaven       PE\n",
      "1496                  Nguyen-Jackson      S4J9L1   West Jennifer       PE\n",
      "1497                      Miller Ltd      L4L3J7     Port Ashley       YT\n",
      "1498                   Parker-Graves     G5X 8Y1   South Zachary       BC\n",
      "1499                       Mason PLC      R2M8T4  Alexanderhaven       SK\n",
      "\n",
      "[1500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker for synthetic data generation\n",
    "fake = Faker('en_CA')  # Use Canadian locale for realistic data\n",
    "\n",
    "# Predefined list of Canadian provinces and territories\n",
    "provinces = [\n",
    "    \"AB\", \"BC\", \"MB\", \"NB\", \"NL\", \"NS\", \"NT\", \"NU\", \"ON\", \"PE\", \"QC\", \"SK\", \"YT\"\n",
    "]\n",
    "\n",
    "# Function to generate realistic business data\n",
    "def generate_realistic_data(num_records: int) -> pd.DataFrame:\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        business_name = fake.company()\n",
    "        postal_code = fake.postalcode()\n",
    "        city = fake.city()\n",
    "        province = random.choice(provinces)\n",
    "        data.append([business_name, postal_code, city, province])\n",
    "    return pd.DataFrame(data, columns=['business_name', 'postal_code', 'city', 'province'])\n",
    "\n",
    "# Function to introduce controlled variations (true matches)\n",
    "def introduce_variations(df: pd.DataFrame, variation_rate: float = 0.1) -> pd.DataFrame:\n",
    "    varied_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        if random.random() < variation_rate:\n",
    "            business_name = vary_string(row['business_name'])\n",
    "            postal_code = vary_string(row['postal_code'])\n",
    "            city = vary_string(row['city'])\n",
    "            province = row['province']  # Assume province remains unchanged\n",
    "            varied_data.append([business_name, postal_code, city, province])\n",
    "        else:\n",
    "            varied_data.append(row.tolist())\n",
    "    return pd.DataFrame(varied_data, columns=['business_name', 'postal_code', 'city', 'province'])\n",
    "\n",
    "# Function to vary strings slightly (simulate typos, abbreviations, etc.)\n",
    "def vary_string(s: str, error_rate: float = 0.1) -> str:\n",
    "    s = list(s)\n",
    "    for i in range(len(s)):\n",
    "        if random.random() < error_rate:\n",
    "            s[i] = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "    return ''.join(s)\n",
    "\n",
    "# Function to create false matches (completely different synthetic records)\n",
    "def generate_false_matches(num_records: int) -> pd.DataFrame:\n",
    "    return generate_realistic_data(num_records)\n",
    "\n",
    "# Main function to generate the final dataset\n",
    "def generate_synthetic_dataset(num_records: int, variation_rate: float = 0.1, false_match_ratio: float = 0.5) -> pd.DataFrame:\n",
    "    # Generate base dataset\n",
    "    base_df = generate_realistic_data(num_records)\n",
    "    \n",
    "    # Introduce variations for true matches\n",
    "    true_matches_df = introduce_variations(base_df, variation_rate)\n",
    "    \n",
    "    # Generate false matches\n",
    "    num_false_matches = int(num_records * false_match_ratio)\n",
    "    false_matches_df = generate_false_matches(num_false_matches)\n",
    "    \n",
    "    # Combine true matches and false matches\n",
    "    combined_df = pd.concat([true_matches_df, false_matches_df]).reset_index(drop=True)\n",
    "    \n",
    "    # Shuffle the combined dataset to mix true and false matches\n",
    "    combined_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Generate the synthetic dataset\n",
    "synthetic_dataset = generate_synthetic_dataset(num_records=1000, variation_rate=0.2, false_match_ratio=0.5)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "synthetic_dataset.to_csv('synthetic_business_dataset.csv', index=False)\n",
    "\n",
    "print(synthetic_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e1c2ff-cb8a-4788-bf34-0b18f262e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "actually I just realized, this my not be the best way to compare word embedding models to traditional methods, the advantage of word embeddings is they understand context, and if we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d4a5f30-ca63-4630-a552-95f60750ce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1:\n",
      "               business_name postal_code               city province\n",
      "0            Collins-Simpson     A7L 1L6  Port Rebekahhaven       PE\n",
      "1             mefersfn-Brswn      f4M9P8     sbw Beverlyttn       PE\n",
      "2  Perez, Howard and Pearson     C9H 2C1       Matthewhaven       YT\n",
      "3                Moss-Becker     K8B 4A9    North Jasonfurt       AB\n",
      "4                Roman-Black     K1V 5R7         Mayborough       PE\n",
      "\n",
      "Dataset 2:\n",
      "              business_name postal_code             city province\n",
      "0  Smith, Patton and Morgan     S5C 8E7       Medinabury       ON\n",
      "1                   Cox LLC      J2Y1P3     North Robert       NU\n",
      "2    Mcclure, Gill and Rose     N4J 6P6      Jenkinsbury       AB\n",
      "3            Price and Sons     A3B 7M8  Lake Aaronmouth       SK\n",
      "4                 Price Ltd      V1R3J2       Craigmouth       NT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker for synthetic data generation\n",
    "fake = Faker('en_CA')  # Use Canadian locale for realistic data\n",
    "\n",
    "# Predefined list of Canadian provinces and territories\n",
    "provinces = [\n",
    "    \"AB\", \"BC\", \"MB\", \"NB\", \"NL\", \"NS\", \"NT\", \"NU\", \"ON\", \"PE\", \"QC\", \"SK\", \"YT\"\n",
    "]\n",
    "\n",
    "# Function to generate realistic business data\n",
    "def generate_realistic_data(num_records: int) -> pd.DataFrame:\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        business_name = fake.company()\n",
    "        postal_code = fake.postalcode()\n",
    "        city = fake.city()\n",
    "        province = random.choice(provinces)\n",
    "        data.append([business_name, postal_code, city, province])\n",
    "    return pd.DataFrame(data, columns=['business_name', 'postal_code', 'city', 'province'])\n",
    "\n",
    "# Function to introduce controlled variations (true matches)\n",
    "def introduce_variations(df: pd.DataFrame, variation_rate: float = 0.1) -> pd.DataFrame:\n",
    "    varied_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        if random.random() < variation_rate:\n",
    "            business_name = vary_string(row['business_name'])\n",
    "            postal_code = vary_string(row['postal_code'])\n",
    "            city = vary_string(row['city'])\n",
    "            province = row['province']  # Assume province remains unchanged\n",
    "            varied_data.append([business_name, postal_code, city, province])\n",
    "        else:\n",
    "            varied_data.append(row.tolist())\n",
    "    return pd.DataFrame(varied_data, columns=['business_name', 'postal_code', 'city', 'province'])\n",
    "\n",
    "# Function to vary strings slightly (simulate typos, abbreviations, etc.)\n",
    "def vary_string(s: str, error_rate: float = 0.1) -> str:\n",
    "    s = list(s)\n",
    "    for i in range(len(s)):\n",
    "        if random.random() < error_rate:\n",
    "            s[i] = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "    return ''.join(s)\n",
    "\n",
    "# Function to create false matches (completely different synthetic records)\n",
    "def generate_false_matches(num_records: int) -> pd.DataFrame:\n",
    "    return generate_realistic_data(num_records)\n",
    "\n",
    "# Main function to generate two datasets for record linkage\n",
    "def generate_linkage_datasets(base_records: int, variation_rate: float = 0.1, false_match_ratio: float = 0.5) -> (pd.DataFrame, pd.DataFrame):\n",
    "    # Generate base dataset\n",
    "    base_df = generate_realistic_data(base_records)\n",
    "    \n",
    "    # Introduce variations for true matches in both datasets\n",
    "    true_matches_df1 = introduce_variations(base_df, variation_rate)\n",
    "    true_matches_df2 = introduce_variations(base_df, variation_rate)\n",
    "    \n",
    "    # Generate false matches\n",
    "    num_false_matches = int(base_records * false_match_ratio)\n",
    "    false_matches_df1 = generate_false_matches(num_false_matches)\n",
    "    false_matches_df2 = generate_false_matches(num_false_matches)\n",
    "    \n",
    "    # Combine true matches and false matches for both datasets\n",
    "    dataset1 = pd.concat([true_matches_df1, false_matches_df1]).reset_index(drop=True)\n",
    "    dataset2 = pd.concat([true_matches_df2, false_matches_df2]).reset_index(drop=True)\n",
    "    \n",
    "    # Shuffle the combined datasets to mix true and false matches\n",
    "    dataset1 = dataset1.sample(frac=1).reset_index(drop=True)\n",
    "    dataset2 = dataset2.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return dataset1, dataset2\n",
    "\n",
    "# Generate the linkage datasets\n",
    "dataset1, dataset2 = generate_linkage_datasets(base_records=1000, variation_rate=0.2, false_match_ratio=0.5)\n",
    "\n",
    "# Save the datasets to CSV files\n",
    "dataset1.to_csv('linkage_dataset1.csv', index=False)\n",
    "dataset2.to_csv('linkage_dataset2.csv', index=False)\n",
    "\n",
    "print(\"Dataset 1:\")\n",
    "print(dataset1.head())\n",
    "print(\"\\nDataset 2:\")\n",
    "print(dataset2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbcd021-f44b-433e-b570-23a631a58adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
