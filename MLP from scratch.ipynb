{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dca4d3e-a3ea-4be2-8ab2-8c3aa5e44abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b9872a-5a28-4308-bc61-84b50870aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4a2e6b-c40e-4b77-857b-d577cdf9fe95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {s: i+1 for i, s in enumerate(sorted(list(set(''.join(words)))))}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a910ba94-d94b-4209-9297-dc03e29920b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '.', '.'] -> e\n",
      "['.', '.', 'e'] -> m\n",
      "['.', 'e', 'm'] -> m\n",
      "['e', 'm', 'm'] -> a\n",
      "['m', 'm', 'a'] -> .\n",
      "['.', '.', '.'] -> o\n",
      "['.', '.', 'o'] -> l\n",
      "['.', 'o', 'l'] -> i\n",
      "['o', 'l', 'i'] -> v\n",
      "['l', 'i', 'v'] -> i\n",
      "['i', 'v', 'i'] -> a\n",
      "['v', 'i', 'a'] -> .\n",
      "['.', '.', '.'] -> a\n",
      "['.', '.', 'a'] -> v\n",
      "['.', 'a', 'v'] -> a\n",
      "['a', 'v', 'a'] -> .\n",
      "['.', '.', '.'] -> i\n",
      "['.', '.', 'i'] -> s\n",
      "['.', 'i', 's'] -> a\n",
      "['i', 's', 'a'] -> b\n",
      "['s', 'a', 'b'] -> e\n",
      "['a', 'b', 'e'] -> l\n",
      "['b', 'e', 'l'] -> l\n",
      "['e', 'l', 'l'] -> a\n",
      "['l', 'l', 'a'] -> .\n",
      "['.', '.', '.'] -> s\n",
      "['.', '.', 's'] -> o\n",
      "['.', 's', 'o'] -> p\n",
      "['s', 'o', 'p'] -> h\n",
      "['o', 'p', 'h'] -> i\n",
      "['p', 'h', 'i'] -> a\n",
      "['h', 'i', 'a'] -> .\n"
     ]
    }
   ],
   "source": [
    "context_length = 3 \n",
    "X, Y = [], []\n",
    "\n",
    "for word in words[:5]:\n",
    "    # initialize the context for the word: \n",
    "    context  = ['.'] * context_length\n",
    "    for ch in word + '.':\n",
    "        X.append([stoi[s] for s in context])\n",
    "        Y.append(stoi[ch])\n",
    "        print(context, '->', ch)\n",
    "        context =  context[1:] + [ch]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "155af736-75d3-4216-857a-95745fe1031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 15],\n",
      "        [ 0, 15, 12],\n",
      "        [15, 12,  9],\n",
      "        [12,  9, 22],\n",
      "        [ 9, 22,  9],\n",
      "        [22,  9,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  1],\n",
      "        [ 0,  1, 22],\n",
      "        [ 1, 22,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  9],\n",
      "        [ 0,  9, 19],\n",
      "        [ 9, 19,  1],\n",
      "        [19,  1,  2],\n",
      "        [ 1,  2,  5],\n",
      "        [ 2,  5, 12],\n",
      "        [ 5, 12, 12],\n",
      "        [12, 12,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 19],\n",
      "        [ 0, 19, 15],\n",
      "        [19, 15, 16],\n",
      "        [15, 16,  8],\n",
      "        [16,  8,  9],\n",
      "        [ 8,  9,  1]])\n",
      "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
      "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "403d9ed0-a3ca-41d3-84a1-93192b33e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding matrix: C: 27,2 \n",
    "C = torch.rand(27,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5904672b-56f1-4d44-b74a-060680ff982d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8008e713-a700-438c-b631-9f532596d61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1681, 0.9909],\n",
       "        [0.1681, 0.9909],\n",
       "        [0.1681, 0.9909]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6f96c-d546-449a-9308-24aa1dae7e07",
   "metadata": {},
   "source": [
    "Embedding Structure:\n",
    "\n",
    "- `C` is an embedding matrix of `(27, 2)`\n",
    "- `X` is list  of context window, where each context is a list of indicies\n",
    "\n",
    "When we do `C[X]` we get tensor shaped `(32, 3, 2)`, where:\n",
    "- the first dimension (32) is the number of context windows\n",
    "- the second dimension (3) is the number of characters in each context window\n",
    "- the third dimension (2) is the dimensionality of the context window\n",
    "\n",
    "We should view `emb` as 3-dimensional tensor where each \"element\" is a `3,2` of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94626a67-4954-4fda-9e89-a5843f815e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8dd64667-770a-47ef-a0f4-0c0b1dafe1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1681, 0.9909],\n",
       "        [0.1681, 0.9909],\n",
       "        [0.1681, 0.9909]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8dd39-9cc0-463e-951e-00b88ce34e03",
   "metadata": {},
   "source": [
    "Neural Networks, particularly MLPs, expect input to be flat vectors. Our new vector represents the entire context window as a single unit of information, which the neural network can process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f7da3da-bcb0-44ba-a5f2-627df699826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1681, 0.9909, 0.1681, 0.9909, 0.1681, 0.9909])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(-1,6)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6be5bc24-23e0-4abd-b2a9-ecd76d33bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn((100))\n",
    "out = emb.view(-1,6) @ W1 + b1\n",
    "W2 = torch.randn((100,27))\n",
    "b2 = torch.randn(27)\n",
    "logits = out @ W2 + b2\n",
    "counts = logits.exp()\n",
    "probs = counts /counts.sum(1, keepdims = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "268aba4a-0139-41b1-b0d6-f6f92b754a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b3c04b7-387d-43cd-8519-a9ff0b2f76e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0012e-23, 1.5547e-22, 5.7554e-25, 5.6777e-25, 3.9090e-14, 2.8465e-16,\n",
       "        9.9962e-01, 1.4990e-11, 4.4908e-28, 5.4308e-04, 7.5388e-19, 2.2951e-11,\n",
       "        3.2417e-20, 2.0056e-17, 8.0035e-18, 1.0065e-09, 3.0842e-07, 2.1833e-17,\n",
       "        3.7064e-22, 1.9988e-15, 7.1823e-23, 1.4927e-09, 4.4547e-07, 1.0946e-30,\n",
       "        1.2979e-15, 2.4256e-17, 4.0404e-14, 5.3734e-11, 2.9308e-15, 9.9549e-06,\n",
       "        5.2579e-22, 2.6991e-08])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b2381-cc44-48d8-b93c-89767700bca1",
   "metadata": {},
   "source": [
    "This gives the probabilities assigned by the neural network to the correct outputs. Now we examine the negative log likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "24b5f719-89fc-486b-8fa6-5e618fb7da32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34.8668)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-probs[torch.arange(32), Y].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "92b3d5e4-6805-4e95-b4ca-2df964cee10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- re-writing -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "446eb8ef-3912-4ed3-a9d4-cfc4ee7227a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))\n",
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn(100)\n",
    "W2= torch.randn(100, 27)\n",
    "b2 = torch.randn(27)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7dfc33-97d6-4902-a316-83df25537a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b0f89fd1-6e8b-434b-ac7e-2d213532ad15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6592eb33-65d4-417c-b506-2438e27ced96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8185)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass:\n",
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 #(32, 27)\n",
    "# counts = logits.exp()\n",
    "# prob = counts / counts.sum(1, keepdims= True)\n",
    "# loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f105f7ff-8a9f-4c06-a0f8-64a71e2f9f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8185)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d957e2db-b7db-4016-b043-16811ed6ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))\n",
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn(100)\n",
    "W2= torch.randn(100, 27)\n",
    "b2 = torch.randn(27)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e322e7-66e3-43f5-94f0-82b3b8fb6b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ae9eb-b454-4df0-af1f-68572238dccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506012ce-debe-44ef-91a0-4347706efa66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d78cb97-f08f-4b58-ad92-e8c6d37a68af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6fd90c6e-618d-4e49-86f6-d1e47982b359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.690547943115234\n",
      "11.096037864685059\n",
      "9.4055757522583\n",
      "8.00573444366455\n",
      "6.8577399253845215\n",
      "5.927469730377197\n",
      "5.188044548034668\n",
      "4.581540107727051\n",
      "4.07319974899292\n",
      "3.641629934310913\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    # forward pass:\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 #(32, 27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None # same as setting it to 0 in Pytorch\n",
    "    loss.backward()\n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "662ba946-e5f8-4b3d-96b9-5d987f6837ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8b0a9-79df-41e8-b7a8-38e0d4b7c47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
