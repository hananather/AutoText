{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dca4d3e-a3ea-4be2-8ab2-8c3aa5e44abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b9872a-5a28-4308-bc61-84b50870aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4a2e6b-c40e-4b77-857b-d577cdf9fe95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {s: i+1 for i, s in enumerate(sorted(list(set(''.join(words)))))}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a910ba94-d94b-4209-9297-dc03e29920b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '.', '.'] -> e\n",
      "['.', '.', 'e'] -> m\n",
      "['.', 'e', 'm'] -> m\n",
      "['e', 'm', 'm'] -> a\n",
      "['m', 'm', 'a'] -> .\n",
      "['.', '.', '.'] -> o\n",
      "['.', '.', 'o'] -> l\n",
      "['.', 'o', 'l'] -> i\n",
      "['o', 'l', 'i'] -> v\n",
      "['l', 'i', 'v'] -> i\n",
      "['i', 'v', 'i'] -> a\n",
      "['v', 'i', 'a'] -> .\n",
      "['.', '.', '.'] -> a\n",
      "['.', '.', 'a'] -> v\n",
      "['.', 'a', 'v'] -> a\n",
      "['a', 'v', 'a'] -> .\n",
      "['.', '.', '.'] -> i\n",
      "['.', '.', 'i'] -> s\n",
      "['.', 'i', 's'] -> a\n",
      "['i', 's', 'a'] -> b\n",
      "['s', 'a', 'b'] -> e\n",
      "['a', 'b', 'e'] -> l\n",
      "['b', 'e', 'l'] -> l\n",
      "['e', 'l', 'l'] -> a\n",
      "['l', 'l', 'a'] -> .\n",
      "['.', '.', '.'] -> s\n",
      "['.', '.', 's'] -> o\n",
      "['.', 's', 'o'] -> p\n",
      "['s', 'o', 'p'] -> h\n",
      "['o', 'p', 'h'] -> i\n",
      "['p', 'h', 'i'] -> a\n",
      "['h', 'i', 'a'] -> .\n"
     ]
    }
   ],
   "source": [
    "context_length = 3 \n",
    "X, Y = [], []\n",
    "\n",
    "for word in words[:5]:\n",
    "    # initialize the context for the word: \n",
    "    context  = ['.'] * context_length\n",
    "    for ch in word + '.':\n",
    "        X.append([stoi[s] for s in context])\n",
    "        Y.append(stoi[ch])\n",
    "        print(context, '->', ch)\n",
    "        context =  context[1:] + [ch]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "155af736-75d3-4216-857a-95745fe1031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 15],\n",
      "        [ 0, 15, 12],\n",
      "        [15, 12,  9],\n",
      "        [12,  9, 22],\n",
      "        [ 9, 22,  9],\n",
      "        [22,  9,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  1],\n",
      "        [ 0,  1, 22],\n",
      "        [ 1, 22,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  9],\n",
      "        [ 0,  9, 19],\n",
      "        [ 9, 19,  1],\n",
      "        [19,  1,  2],\n",
      "        [ 1,  2,  5],\n",
      "        [ 2,  5, 12],\n",
      "        [ 5, 12, 12],\n",
      "        [12, 12,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 19],\n",
      "        [ 0, 19, 15],\n",
      "        [19, 15, 16],\n",
      "        [15, 16,  8],\n",
      "        [16,  8,  9],\n",
      "        [ 8,  9,  1]])\n",
      "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
      "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "403d9ed0-a3ca-41d3-84a1-93192b33e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding matrix: C: 27,2 \n",
    "C = torch.rand(27,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5904672b-56f1-4d44-b74a-060680ff982d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8008e713-a700-438c-b631-9f532596d61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1681, 0.9909],\n",
       "        [0.1681, 0.9909],\n",
       "        [0.1681, 0.9909]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6f96c-d546-449a-9308-24aa1dae7e07",
   "metadata": {},
   "source": [
    "Embedding Structure:\n",
    "\n",
    "- `C` is an embedding matrix of `(27, 2)`\n",
    "- `X` is list  of context window, where each context is a list of indicies\n",
    "\n",
    "When we do `C[X]` we get tensor shaped `(32, 3, 2)`, where:\n",
    "- the first dimension (32) is the number of context windows\n",
    "- the second dimension (3) is the number of characters in each context window\n",
    "- the third dimension (2) is the dimensionality of the context window\n",
    "\n",
    "We should view `emb` as 3-dimensional tensor where each \"element\" is a `3,2` of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94626a67-4954-4fda-9e89-a5843f815e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8dd64667-770a-47ef-a0f4-0c0b1dafe1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1681, 0.9909],\n",
       "        [0.1681, 0.9909],\n",
       "        [0.1681, 0.9909]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8dd39-9cc0-463e-951e-00b88ce34e03",
   "metadata": {},
   "source": [
    "Neural Networks, particularly MLPs, expect input to be flat vectors. Our new vector represents the entire context window as a single unit of information, which the neural network can process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f7da3da-bcb0-44ba-a5f2-627df699826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1681, 0.9909, 0.1681, 0.9909, 0.1681, 0.9909])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(-1,6)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6be5bc24-23e0-4abd-b2a9-ecd76d33bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn((100))\n",
    "out = emb.view(-1,6) @ W1 + b1\n",
    "W2 = torch.randn((100,27))\n",
    "b2 = torch.randn(27)\n",
    "logits = out @ W2 + b2\n",
    "counts = logits.exp()\n",
    "probs = counts /counts.sum(1, keepdims = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "268aba4a-0139-41b1-b0d6-f6f92b754a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b3c04b7-387d-43cd-8519-a9ff0b2f76e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0012e-23, 1.5547e-22, 5.7554e-25, 5.6777e-25, 3.9090e-14, 2.8465e-16,\n",
       "        9.9962e-01, 1.4990e-11, 4.4908e-28, 5.4308e-04, 7.5388e-19, 2.2951e-11,\n",
       "        3.2417e-20, 2.0056e-17, 8.0035e-18, 1.0065e-09, 3.0842e-07, 2.1833e-17,\n",
       "        3.7064e-22, 1.9988e-15, 7.1823e-23, 1.4927e-09, 4.4547e-07, 1.0946e-30,\n",
       "        1.2979e-15, 2.4256e-17, 4.0404e-14, 5.3734e-11, 2.9308e-15, 9.9549e-06,\n",
       "        5.2579e-22, 2.6991e-08])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b2381-cc44-48d8-b93c-89767700bca1",
   "metadata": {},
   "source": [
    "This gives the probabilities assigned by the neural network to the correct outputs. Now we examine the negative log likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "24b5f719-89fc-486b-8fa6-5e618fb7da32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34.8668)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-probs[torch.arange(32), Y].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "92b3d5e4-6805-4e95-b4ca-2df964cee10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- re-writing -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "446eb8ef-3912-4ed3-a9d4-cfc4ee7227a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))\n",
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn(100)\n",
    "W2= torch.randn(100, 27)\n",
    "b2 = torch.randn(27)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0f89fd1-6e8b-434b-ac7e-2d213532ad15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6592eb33-65d4-417c-b506-2438e27ced96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8185)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass:\n",
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 #(32, 27)\n",
    "# counts = logits.exp()\n",
    "# prob = counts / counts.sum(1, keepdims= True)\n",
    "# loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f105f7ff-8a9f-4c06-a0f8-64a71e2f9f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8185)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "58f1b9db-57f6-4c1f-bcae-38beff8675b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8185)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6fd90c6e-618d-4e49-86f6-d1e47982b359",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m      8\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# same as setting it to 0 in Pytorch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m     11\u001b[0m     p\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/Desktop/AutoText/venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AutoText/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AutoText/venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    # forward pass:\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 #(32, 27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print()\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None # same as setting it to 0 in Pytorch\n",
    "    loss.backward()\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d78cb97-f08f-4b58-ad92-e8c6d37a68af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
