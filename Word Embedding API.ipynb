{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ace28d-785a-48bd-9361-fb92660a488d",
   "metadata": {},
   "source": [
    "# What are embeddings?\n",
    "- Embeddings are a fundamental concept from natural language processings; where words, phrases, or entire documents are represented in numerical form.\n",
    "- More fundamentally, embeddings models  map text onto a multi-dimensional space, or vector space, and the numbers outputted by the model represent the location of the text in that space.\n",
    "- Simillar pieces of text or words, like teacher and student, are mapped closer together in the space and dissimilar words are mapped futher away.\n",
    "- this abilitity  to map similar and dissimilar words means that embedding models can be used to capture the **semantic meaning** of text. (by semantic meaning, we mean the full context and intent of the word is captured)\n",
    "- \"which way is to the supermarkey\" vs. \"Could I have directions to the shop\" only have two words in common but semantically very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfd489f-3683-4197-aa13-0829e969e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['name1'] = df['name1'].str.lower().str.strip()\n",
    "    df['name2'] = df['name2'].str.lower().str.strip()\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a3cdc20-ce2c-4401-900b-cf5c3c58e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def levenshtein_distance(str1, str2):\n",
    "    distance = Levenshtein.distance(str1, str2)\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    return distance / max_len\n",
    "\n",
    "def n_gram_similarity(str1, str2, n=3):\n",
    "    str1_ngrams = set(ngrams(str1, n))\n",
    "    str2_ngrams = set(ngrams(str2, n))\n",
    "    return len(str1_ngrams & str2_ngrams) / float(len(str1_ngrams | str2_ngrams))\n",
    "\n",
    "def jaro_winkler_similarity(str1, str2):\n",
    "    return Levenshtein.jaro_winkler(str1, str2)\n",
    "\n",
    "def tfidf_cosine_similarity(corpus):\n",
    "    vectorizer = TfidfVectorizer().fit_transform(corpus)\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f8a681e-772b-4a96-a7bb-1f93e684e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "class HuggingFaceEmbedding:\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\", api_key=None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=api_key)\n",
    "        self.model = AutoModel.from_pretrained(model_name, use_auth_token=api_key)\n",
    "\n",
    "    def get_embedding(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors='pt')\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "244c8d1e-f450-4131-a917-cd34ad49df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def compare_algorithms(df):\n",
    "    results = []\n",
    "\n",
    "    hf_embedding = HuggingFaceEmbedding(api_key=\"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\")\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        name1 = row['name1']\n",
    "        name2 = row['name2']\n",
    "\n",
    "        lev_dist = levenshtein_distance(name1, name2)\n",
    "        ngram_sim = n_gram_similarity(name1, name2)\n",
    "        jw_sim = jaro_winkler_similarity(name1, name2)\n",
    "\n",
    "        emb1 = hf_embedding.get_embedding(name1)\n",
    "        emb2 = hf_embedding.get_embedding(name2)\n",
    "        embedding_sim = cosine_similarity(emb1, emb2)[0, 0]\n",
    "\n",
    "        results.append({\n",
    "            \"name1\": name1,\n",
    "            \"name2\": name2,\n",
    "            \"levenshtein_distance\": lev_dist,\n",
    "            \"n_gram_similarity\": ngram_sim,\n",
    "            \"jaro_winkler_similarity\": jw_sim,\n",
    "            \"embedding_similarity\": embedding_sim\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "918be3f9-dd35-4734-bb3f-9e9a5c036a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(\"data/sample_data.csv\")\n",
    "df = preprocess_data(df)\n",
    "#results = compare_algorithms(df)\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a478abf-d10e-43ae-a7b4-0a8b768b0ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name1</th>\n",
       "      <th>name2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple inc.</td>\n",
       "      <td>apple incorporated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google llc</td>\n",
       "      <td>googol l.l.c.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft corporation</td>\n",
       "      <td>micro soft corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon.com inc.</td>\n",
       "      <td>amazon incorporated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook inc.</td>\n",
       "      <td>face book incorporated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>netflix, inc.</td>\n",
       "      <td>net flix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tesla, inc.</td>\n",
       "      <td>teslar inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oracle corporation</td>\n",
       "      <td>orakel corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ibm</td>\n",
       "      <td>international business machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adobe systems inc.</td>\n",
       "      <td>adoby systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>statistics canada</td>\n",
       "      <td>statcan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>canada revenue agency</td>\n",
       "      <td>cra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>environment and climate change canada</td>\n",
       "      <td>eccc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>health canada</td>\n",
       "      <td>hc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>public services and procurement canada</td>\n",
       "      <td>pspc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shopify inc.</td>\n",
       "      <td>shopify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>royal bank of canada</td>\n",
       "      <td>rbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>brookfield asset management</td>\n",
       "      <td>brookfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>canadian national railway</td>\n",
       "      <td>cn railway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>thomson reuters</td>\n",
       "      <td>thomson reuters corp.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name1                            name2\n",
       "0                               apple inc.               apple incorporated\n",
       "1                               google llc                    googol l.l.c.\n",
       "2                    microsoft corporation                  micro soft corp\n",
       "3                          amazon.com inc.              amazon incorporated\n",
       "4                            facebook inc.           face book incorporated\n",
       "5                            netflix, inc.                         net flix\n",
       "6                              tesla, inc.                      teslar inc.\n",
       "7                       oracle corporation                     orakel corp.\n",
       "8                                      ibm  international business machines\n",
       "9                       adobe systems inc.                    adoby systems\n",
       "10                       statistics canada                          statcan\n",
       "11                   canada revenue agency                              cra\n",
       "12   environment and climate change canada                             eccc\n",
       "13                           health canada                               hc\n",
       "14  public services and procurement canada                             pspc\n",
       "15                            shopify inc.                          shopify\n",
       "16                    royal bank of canada                              rbc\n",
       "17             brookfield asset management                       brookfield\n",
       "18               canadian national railway                       cn railway\n",
       "19                         thomson reuters            thomson reuters corp."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b953808-4140-4de2-8cd4-275f8b77db27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hananather/Desktop/AutoText/venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:778: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/Users/hananather/Desktop/AutoText/venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     name1                            name2  \\\n",
      "0                               apple inc.               apple incorporated   \n",
      "1                               google llc                    googol l.l.c.   \n",
      "2                    microsoft corporation                  micro soft corp   \n",
      "3                          amazon.com inc.              amazon incorporated   \n",
      "4                            facebook inc.           face book incorporated   \n",
      "5                            netflix, inc.                         net flix   \n",
      "6                              tesla, inc.                      teslar inc.   \n",
      "7                       oracle corporation                     orakel corp.   \n",
      "8                                      ibm  international business machines   \n",
      "9                       adobe systems inc.                    adoby systems   \n",
      "10                       statistics canada                          statcan   \n",
      "11                   canada revenue agency                              cra   \n",
      "12   environment and climate change canada                             eccc   \n",
      "13                           health canada                               hc   \n",
      "14  public services and procurement canada                             pspc   \n",
      "15                            shopify inc.                          shopify   \n",
      "16                    royal bank of canada                              rbc   \n",
      "17             brookfield asset management                       brookfield   \n",
      "18               canadian national railway                       cn railway   \n",
      "19                         thomson reuters            thomson reuters corp.   \n",
      "\n",
      "    levenshtein_distance  n_gram_similarity  jaro_winkler_similarity  \\\n",
      "0               0.500000           0.411765                 0.880000   \n",
      "1               0.384615           0.117647                 0.918462   \n",
      "2               0.380952           0.454545                 0.891429   \n",
      "3               0.578947           0.250000                 0.826093   \n",
      "4               0.454545           0.347826                 0.860373   \n",
      "5               0.538462           0.214286                 0.851923   \n",
      "6               0.090909           0.500000                 0.963636   \n",
      "7               0.555556           0.190476                 0.834074   \n",
      "8               0.903226           0.000000                 0.577061   \n",
      "9               0.333333           0.421053                 0.884615   \n",
      "10              0.588235           0.176471                 0.882353   \n",
      "11              0.857143           0.000000                 0.603175   \n",
      "12              0.891892           0.000000                 0.518018   \n",
      "13              0.846154           0.000000                 0.525641   \n",
      "14              0.894737           0.000000                 0.618421   \n",
      "15              0.416667           0.500000                 0.916667   \n",
      "16              0.850000           0.000000                 0.588889   \n",
      "17              0.629630           0.320000                 0.874074   \n",
      "18              0.600000           0.240000                 0.564762   \n",
      "19              0.285714           0.684211                 0.942857   \n",
      "\n",
      "    embedding_similarity  \n",
      "0               0.891946  \n",
      "1               0.507944  \n",
      "2               0.812509  \n",
      "3               0.779390  \n",
      "4               0.788614  \n",
      "5               0.703022  \n",
      "6               0.905813  \n",
      "7               0.750406  \n",
      "8               0.775839  \n",
      "9               0.745221  \n",
      "10              0.749285  \n",
      "11              0.644628  \n",
      "12              0.600861  \n",
      "13              0.789979  \n",
      "14              0.613569  \n",
      "15              0.874833  \n",
      "16              0.646269  \n",
      "17              0.807272  \n",
      "18              0.880164  \n",
      "19              0.876252  \n"
     ]
    }
   ],
   "source": [
    "df = load_data(\"data/sample_data.csv\")\n",
    "df = preprocess_data(df)\n",
    "results = compare_algorithms(df)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18db30a-d74a-498f-8de6-d62ea77f81cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
