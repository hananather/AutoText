{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "047c5e30-a25c-4596-b77e-840c12c593de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbcca382-885c-400c-a938-81e230dce0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f6ef126-9010-44f8-9f7f-76034dd6ec9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build vocab of words\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i +1 for i,s in enumerate(chars)}\n",
    "stoi ['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12bb198e-4f44-4733-9668-6d57d56fb390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... --> e\n",
      "..e --> m\n",
      ".em --> m\n",
      "emm --> a\n",
      "mma --> .\n",
      "... --> o\n",
      "..o --> l\n",
      ".ol --> i\n",
      "oli --> v\n",
      "liv --> i\n",
      "ivi --> a\n",
      "via --> .\n",
      "... --> a\n",
      "..a --> v\n",
      ".av --> a\n",
      "ava --> .\n",
      "... --> i\n",
      "..i --> s\n",
      ".is --> a\n",
      "isa --> b\n",
      "sab --> e\n",
      "abe --> l\n",
      "bel --> l\n",
      "ell --> a\n",
      "lla --> .\n",
      "... --> s\n",
      "..s --> o\n",
      ".so --> p\n",
      "sop --> h\n",
      "oph --> i\n",
      "phi --> a\n",
      "hia --> .\n"
     ]
    }
   ],
   "source": [
    "# building the context window\n",
    "X,Y = [], []\n",
    "context_size = 3\n",
    "\n",
    "for word in words[:5]:\n",
    "    context = [0] * context_size # re-initalize the context for each word\n",
    "    for ch in word + '.':\n",
    "        # convert the ch to interger\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(\"\".join(itos[i] for i in context), '-->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "X = torch.tensor(X)\n",
    "Y =  torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9564100-f515-4074-a227-d59bd5dfd8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d16ef613-4f0a-4c7b-ad40-f1a58407ddf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1222, 0.6176])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0e3098d-c34d-4338-ab53-12c9f4ce48fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1222, 0.6176])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes = 27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "94d70e45-21d5-4d88-8260-8a73a54fa79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba376b67-7805-4994-b64e-9dfff9cc09a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[13,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd8711e8-9b32-401c-8302-72ba2e460d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474cdd1c-5a48-4054-8566-ad2daccdfdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5969adb-bb4c-43b9-bdfc-e4b4a8fd5ccf",
   "metadata": {},
   "source": [
    "we have 3 words as input: each word has a 2d embedding. \n",
    "\n",
    "Trainig dataset X: (N,3) - each word is represented by an index but each index actually corresponds to a 2D vector. \n",
    "\n",
    "C (look up)- is (27, 2) - each character is represented by a 2D row.\n",
    "\n",
    "The neural network will take 3 words has inputs where each word is represented by a 2D vector.\n",
    "Therefore the input is actually 3 vectors that that are 2x1 each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e019869-0b48-44e2-835c-48a1e405c69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6093, 0.2906],\n",
       "        [0.6093, 0.2906],\n",
       "        [0.6093, 0.2906]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][0] # this is the embedding rep of  0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "513549ca-0fcd-4160-be7c-4f9148f8c4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "757992db-f5ee-4842-b6c0-ea9bcb0aada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "701fd69a-3b67-442e-a918-98ff656a880c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.2631e-01,  1.2592e+00, -3.1391e-01, -2.3158e+00,  5.5852e-02,\n",
       "        -4.3301e-01, -1.0031e+00,  2.4420e+00, -1.3918e+00,  5.9667e-01,\n",
       "        -1.4062e+00,  7.5446e-01,  4.4328e-02,  5.1265e-01, -7.6608e-01,\n",
       "         6.7884e-01, -8.8897e-01,  1.4501e+00,  8.5490e-01,  8.0265e-01,\n",
       "         1.4870e+00, -2.5551e-01, -4.1253e-01, -1.3945e-02,  6.7045e-01,\n",
       "        -1.3455e-01, -1.9233e-01,  3.6077e+00,  1.4214e+00,  9.3722e-01,\n",
       "        -1.0542e-01, -3.6059e-02, -7.2792e-02,  3.0792e-01,  3.5280e-01,\n",
       "         7.7087e-01, -9.1241e-01, -7.4117e-01, -1.5080e+00,  2.6585e-01,\n",
       "         9.0664e-02,  6.2571e-03, -2.6252e-02,  6.4823e-01, -1.2180e+00,\n",
       "         1.4476e-02, -9.1479e-01, -1.3511e+00, -5.9680e-01,  9.1080e-01,\n",
       "        -9.0208e-01, -1.4956e+00,  4.1448e-01, -3.1036e-01,  1.4176e-01,\n",
       "        -9.7890e-01,  1.0526e+00, -1.7523e+00,  9.6592e-01, -1.5601e+00,\n",
       "        -7.5268e-01, -4.6281e-01,  2.2448e-01,  7.1603e-01,  1.7116e+00,\n",
       "        -2.1605e+00, -6.9811e-02, -4.3650e-02,  1.9134e+00,  4.3236e-03,\n",
       "        -2.8482e-03,  6.8550e-01, -4.0518e-01,  5.2270e-01, -1.2105e+00,\n",
       "         1.1725e+00,  6.3556e-01,  2.2223e+00, -1.5295e-01,  3.8293e-01,\n",
       "        -2.4380e-01,  5.2184e-02, -7.2375e-01,  2.0065e+00, -8.9697e-02,\n",
       "         6.6394e-01, -6.5844e-01, -2.3511e+00, -1.2776e+00, -3.8716e-01,\n",
       "        -8.6719e-01, -2.1616e+00, -2.9519e-01, -8.8100e-01,  8.5608e-01,\n",
       "         1.5597e+00, -1.0446e+00, -4.0940e-01,  2.4752e-01,  1.6750e-01])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc6f32-7b5c-4fad-b6a1-7476a79cb1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
